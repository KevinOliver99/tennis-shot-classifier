# Tennis Shot Classifier

This project provides a complete pipeline for analyzing tennis broadcast recordings, extracting player poses, and training a classifier to identify different types of tennis shots.

## Setup

This pipeline requires a conda environment with Python 3.10.14 and several dependencies.

### 1. Create and Activate Conda Environment
```bash
conda create -n TennisShotClassifier python=3.10.14
conda activate TennisShotClassifier
```

### 2. Install PyTorch (GPU support recommended)
For CUDA 11.8 (check your CUDA version with `nvidia-smi`):
```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

### 3. Install OpenCV
```bash
conda install opencv -c conda-forge
```

### 4. Install FFmpeg System Binary
```bash
conda install ffmpeg -c conda-forge -y
```

### 5. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 6. Verify Installation
Run the following command to check if all dependencies are installed correctly:
```bash
python -c "import torch, cv2, ultralytics, librosa, sklearn, matplotlib, Sports2D; print('All dependencies installed successfully!')"
yt-dlp --version
sports2d --help
ffmpeg -version
```
> **Note:** If any individual tools or libraries fail, they may need to be installed externally.

---

## Data Generation Pipeline

The project includes 4 tennis broadcast recordings used for creating the pipeline in `Data\Full Recordings`. It also contains a dataset of roughly 3000 normalized pose sequences in `Data\Poses`, along with `Data\shot_annotations.json`.

### 1. Download Data
Download full match broadcasts from YouTube as separate MP4 and MP3 files inside a dedicated subdirectory of `Data\Full Recording`.

**Video:**
```bash
yt-dlp -f bestvideo --cookies "path/to/cookies.txt" -o "filename" "URL"
```

**Audio:**
```bash
yt-dlp -f bestaudio --cookies "path/to/cookies.txt" -o "filename" "URL"
```

> **Note on Cookies:** A `cookies.txt` file is required in the parent folder (exported from Google Chrome using an extension like "Get cookies.txt LOCALLY"). Alternatively, use other online tools to download the MP4/MP3 files.

### 2. Extract Shots
Run the script to automatically identify and extract short clips of individual shots from videos in `Data\Full Recording`:
```bash
python extractShots.py
```

### 3. Label Data
Launch the GUI to manually label the extracted shots. Metadata and labels are saved to `shot_annotations.json`.
```bash
python label.py
```

### 4. Extract Poses
Transform video data into sequential pose data:
```bash
extractPoses.bat
```

### 5. Preprocess Poses
Normalize pose sequences to make them comparable for the model:
```bash
python preprocessPoses.py
```

---

## Training

Train the classifier network using the text files in `Data\Poses`.
```bash
python train.py
```
*   **Output:** The model is saved as `model.pth`.
*   **Logs:** Training progress is logged in text files.
*   **Analysis:** Check `incorrect_predictions.txt` for misclassified files and `validation_and_test_results.txt` for a full log.

---

## Visualization

Visualize the training accuracy log:
```bash
python plot_val_acc_log.py
```
Ensure `val_acc_log.txt` is in the parent directory.

---

## Validation

Validate the model against a specific pose file:
```bash
python validate.py "Data\poses\ abcd1234.txt"
```
*   Ensure `model.pth` is in the parent directory.
*   **Note:** Filenames generated by this pipeline may start with a space.

---

## Examples

Sample training results are provided in the `Example 1` and `Example 2` directories. To use one of these models for validation or further training, copy the corresponding `model.pth` file into the parent directory.
